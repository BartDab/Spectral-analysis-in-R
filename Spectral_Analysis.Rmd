---
title: "Projekt - Analiza Spektralna"
author: "Bartosz Dąbrowski"
date: "6 02 2020"
output: html_document
---

Dane pochodzą z serwisu kaggle.com, zawierającego, pośród wielu różnych wartościowych materiałów, zbiory danych do przeprwoadzania własnych analiz. Wykorzystywany przez nas dataset to informacje dotyczące godzinowego zużycia energii w megawatach (MW) z kilku stanów USA, w których za dystrybucję odpowiedzialny było PJM Interconnection LLC, pobrane ze strony przedsiębiorstwa. Zdecydowaliśmy się na analizę zużycia energii w mieście Dayton, w stanie Ohio - liczącym ok. 170 tys. mieszkańców (850 tys. w ramach obszaru metropolitarnego).

```{r}
library(oce)
library(outliers)
library(lattice)
library(lubridate)
library(multitaper)
require(multitaper)
require(xts)
require(forecast)

```

Dane z dokładnością godzinową mają dużą wartość, ale również mocno komplikują sprawę. Ze względu na duży zakres czasu zdecydowaliśmy się skumulować je do sum dziennych i skupić na szukaniu prawidłowości większych niż dobowe. Ostatnia obserwacja została usunięta, gdyż były to dane z 3 sierpnia 2018, zawierające zużycie energii tylko do godziny 01:00, a więc wyraźnie odstające od reszty wartości.

```{r}

rm(list=ls())
data<-read.csv('DAYTON_hourly.csv',header=TRUE)#,ststringsAsFactors = FALSE)
str(data)
data$Datetime<-as.Date(data$Datetime)
data<-aggregate(DAYTON_MW~Datetime,data,sum)
data<-data[1:5054,]
head(data)
```

W oparciu o pakiet __lubridate__ tworzymy szereg czasowy z naszych danych.

```{r}
data_ts<-ts(data$DAYTON_MW,start=c(year(min(data$Datetime)),yday(min(data$Datetime))),frequency=365)
```

Wizualizujemy dane. Ostatnia obserwacja została usunięte

```{r}
plot(data_ts, type="l", ylab="Energy consumption",xlab="Time",col=grey(.05))
grid()
```

Kolejnymi etapami są dekompozycja szeregu czasowego oraz usunięcie trendu.

```{r}
data_decomposed<-decompose(data_ts)
plot(data_decomposed)
data_trend<-diff(ts(log(data_ts)))
plot(data_trend)
```

Tworzymy periodogram naiwny dla danych bez trendu.

```{r}
periodogram <- spec.pgram(data_trend,log='no', taper=0,pad=0, fast=FALSE,demean=FALSE,detrend=TRUE)
```

Widoczne są wyraźne piki dla 3 wartości - w przybliżeniu 0,14 (cykl tygodniowy), 0,28 oraz 0,43 (cykl ok 2,5- i 3,5-dobowe). O ile pozostałe 2 wydają się dość nieoczywiste, główny jest jak najbardziej naturalny i logiczny.

```{r}
#WYGLADZANIE SREDNIA RUCHOMA:
#tu myślę czy nie rozdziliB
plot(data_trend,type="l")
grid()
#wygladzenie srednia ruchoma rzedu 2
f2<-c(1/4,0.5,1/4)
d2 <-filter(data_trend,f2,sides=2)
lines(d2, col="yellow")
#wygladzenie srednia ruchoma rzedu 3
f3<-c(1/3,1/3,1/3)
d3<-filter(data_trend,f3,sides=2)
lines(d3, col="blue")
#wygladzenie srednia ruchoma rzedu 4
f4<-c(1/8,1/4,1/4,1/4,1/8)
d4 <-filter(data_trend,f4,sides=2)
lines(d4, col="orange")
#wygladzenie srednia ruchoma rzedu 5
f5<-c(1/5,1/5,1/5,1/5,1/5)
d5 <-filter(data_trend,f5,sides=2)
lines(d5, col="green")
#wygladzanie srednia ruchoma rzedu 7
f7<-rep(1/7,7)
d7<-filter(data_trend,f7,sides=2)
lines(d7,col="brown")
#wygladzanie srednia ruchoma rzedu 10
f10<-rep(1/10,10)
d10<-filter(data_trend,f10,sides=2)
lines(d10,col="purple")
#wygladzanie srednia ruchoma rzedu 365
f365<-rep(1/365,365)
d365<-filter(data_trend,f365,sides=2)
lines(d365,col="red")
```

Najlepiej sprawuje się 

```{r}
dane3<-d365[183:4870]
plot(dane3,type="l",col="red")

#DO SPRAWDZENIA

```

```{r}
#PERIODOGRAM NAIWNY:
P<- spec.pgram(data,log='no', taper=0,pad=0, fast=FALSE,demean=FALSE,detrend=TRUE)
abline(v=1/180,lty='dotted',col="red")
abline(v=0.142,lty='dotted',col="grey")
abline(v=0.285,lty='dotted',col="grey")
```


